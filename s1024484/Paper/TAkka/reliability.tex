\begin{table*}[t]
\label{chaos}

\begin{center}
\begin{tabular}{| c | p{4.6 cm} | p{8 cm} | }
\hline
Mode & Failure & Description \\
\hline
Random (Default) & Random Failures & Randomly choose one of the other modes in 
each run. \\
\hline
Exception & Raise an exception & A victim actor randomly raise an exception 
from 
a user-defined set of exceptions. \\
\hline
Kill & Failures that can be recovered by scheduling service restart &  
Terminate 
a victim actor.  The victim actor can be restarted later. \\
\hline
PoisonKill & Unidentifiable failures & Permanently terminate a victim actor.  
The victim cannot be restarted.  \\ 
\hline 
NonTerminate & Design flaw or network congestion & Let a victim actor run 
into an infinite loop.  The victim actor consumes system resources but cannot 
process any messages. \\
\hline

\end{tabular}
\caption{TAkka Chaos Monkey Modes}
\end{center}
\end{table*}



\subsection{Assessing System Reliability}
\label{reliability}

The supervision tree principle is adopted by Erlang and Akka users with the 
hope of improving the reliability of software applications.  Apart from the 
reported nine "9"s reliability of the Ericsson AXD 301 switch 
\cite{ArmstrongAXD} and the wide range of Akka use cases, how can software 
developers assure the reliability of their newly implemented applications?  

TAkka is shipped with a Chaos Monkey library and a Supervision View library for 
assessing the reliability of TAkka applications.  A Chaos Monkey test randomly 
kills actors in a supervision tree and a Supervision View test dynamically 
captures the structure of supervision trees.  With the help of Chaos Monkey and 
Supervision View, users can visualize how their TAkka applications react to 
adverse conditions. Missing nodes in the supervision tree (Section 
\ref{calculator_chaos_test}) show that failures occur during the test. On the 
other hand, any failed actors are restored, and hence appropriately supervised 
applications (Section\ref{bencherl_chaos_test})  pass Chaos Monkey tests.

\begin{comment}

\begin{figure}[h]
\label{chaos_api}
\begin{lstlisting}
class ChaosMonkey(victims:List[ActorRef[_]], exceptions:List[Exception]){
  private var status:Status = OFF;
  
  def setMode(mode:ChaosMode);
  def enableDebug();
  def disableDebug();
  def start(interval:FiniteDuration)  = status match {
    case ON => 
throw new Exception("ChaosMonkey is running: turn it off before restart it.") 
    case OFF =>
      status = ON
      scala.concurrent.future {
        repeat(interval)
      }
  }
  def turnOff()= {status = OFF}
  
  private def once() {
    var tempMode = mode
    if (tempMode == Random){
      tempMode = Random.shuffle(
                 ChaosMode.values.-(Random).toList).head
    }
    val victim = scala.util.Random.shuffle(victims).head
    tempMode match {
      case PoisonKill =>
        victim.untypedRef ! akka.actor.PoisonPill
      case Kill =>
        victim.untypedRef ! akka.actor.Kill
      case Exception =>
        val e = scala.util.Random.shuffle(exceptions).head
        victim.untypedRef ! ChaosException(e)
      case NonTerminate =>
        victim.untypedRef ! ChaosNonTerminate
    }
  }
  
  private def repeat(period:FiniteDuration):Unit =  status match {
    case ON =>
      once
      Thread.sleep(period.toMillis)
      repeat(period)      
    case OFF =>
  } 
}

object ChaosMode extends Enumeration {
    type ChaosMode = Value
    val Random, PoisonKill, Kill, Exception, NonTerminate  = Value
}
\end{lstlisting}
\caption{TAkka Chaos Monkey}
\end{figure}

\end{comment}

\subsubsection {Chaos Monkey and Supervision View}

A Chaos Monkey test \cite{ChaosMonkey} randomly kills Amazon EC2 instances in 
an Auto Scaling Group.  In a Chaos Monkey test, the 
reliability of an application is tested against intensive adverse 
conditions.  Chaos Monkey is ported into Erlang to detect potential flaws of 
supervision trees \cite{ErlangChaosMonkey}.  We port the Erlang version of Chaos 
Monkey into the TAkka library.  In addition to randomly killing actors, users 
can simulate other common failures by using other modes in Table \ref{chaos}.



\begin{comment}
Figure \ref{chaos_api} gives the API and the core implemention of TAkka Chaos 
Monkey.  A user sets up a Chaos Monkey test by initializing a 
{\tt ChaosMonkey} instance, defining the test mode, and scheduling the interval 
between each run.  In each run, the {\tt ChaosMonkey} instance sends a 
randomly picked actor a special message.  When receive a Chaos Monkey message, 
a TAkka actor excute a corresponding potentially problematic code as described 
in Table \ref{chaos}.  {\tt PoisonPill} and {\tt Kill} are handled by {\tt 
systemMessageHandler} and can 
be overrided as described in Section \ref{systemmessage}.  {\tt ChaosException} 
and {\tt ChaosNonTerminate}, on the other hand, are handled by the TAkka 
library and cannot be overrided.




\subsubsection{Supervision View}
\end{comment}
To dynamically monitor changes of supervision trees, we design and implement 
a Supervision View library. In a supervision view test, an instance of {\tt 
ViewMaster} periodically sends request messages to interested actors.  At the 
time when the request message is received, an active TAkka actor replies wih 
its status to the {\tt ViewMaster} instance and passes the request message to 
its children.  The status message includes its actor path, the paths of its 
children, and the time when the reply is sent.  The {\tt ViewMaster} instance 
records status messages and passes them to a visualizer, which will analyze and 
interpret changes of the tree structure during the testing period.  We believe 
that similar library can be straightforwardly implemented in actor systems such 
as Akka and Erlang.  From a practical point of view, the dynamically actor 
monitoring overcomes the two limitations of the static analyses tool 
developed in Nystr√∂m's PhD thesis \cite{JanHenry}, which only applies to 
applications built using the Erlang/OTP library and cannot tell whether 
an actor will actually be started at runtime.

\begin{comment}
A view master is initialized by calling one of the apply method of the {\tt 
ViewMaster} object as given in Figure \ref{supervision_view}.
Each view master has an actor system and a master actor as its fields.  The 
actor system is set up according to the given {\tt name} and {\tt config}, or 
the default configuration.  The master actor, created in the actor system, has 
type {\tt TypedActor[SupervisionViewMessage]}.  After the start method of a 
view master is called, the view master periodcally sends {\tt 
SupervisionViewRequest} to interested nodes in supervision trees, where 
{\tt date} is the system time just before the view master sends requests.  
When a TAkka actor receives {\tt SupervisionViewRequest} message, it sends a 
{\tt SupervisionViewResponse} message back to the view master and pass the \\ 
{\tt SupervisionViewRequest} message to its children.  The {\tt date} value
in a {\tt SupervisionViewResponse} message is the same as the {\tt date} value 
in the corresponding {\tt SupervisionViewRequest} message.  Finally, the master 
actor of the view master records all replies in a hash map from {\tt Date} to 
{\tt TreeSet[NodeRecord]}, and sends the record to appropriate drawer on 
request. 



\begin{figure}[h]
\label{supervision_view}
\begin{lstlisting}
sealed trait SupervisionViewMessage
case class SupervisionViewResponse(date:Date, reportorPath:ActorPath, childrenPath:List[ActorPath]) extends SupervisionViewMessage
case class ReportViewTo(drawer:ActorRef[Map[Date, TreeSet[NodeRecord]]]) extends  SupervisionViewMessage

case class SupervisionViewRequest(date:Date,  master:ActorRef[SupervisionViewResponse])
case class NodeRecord(receiveTime:Date, node:ActorPath, childrenPath:List[ActorPath]) 

object ViewMaster{
  def apply(name:String, config: Config, topnodes:List[ActorRef[_]], interval:FiniteDuration):ViewMaster
  
  def apply(name:String, topnodes:List[ActorRef[_]], interval:FiniteDuration):ViewMaster
  
  def apply(topnodes:List[ActorRef[_]], interval:FiniteDuration):ViewMaster
}


\end{lstlisting}
\caption{Supersion View}
\end{figure}
\end{comment}

\begin{figure*}[t]
     \begin{center}
        \subfigure[]{
            \label{fig:tree1}
            \includegraphics[scale=0.33]{Tree1.png}
        }
        \subfigure[]{
           \label{fig:tree2}
           \includegraphics[scale=0.33]{Tree2.png}
        }
        \subfigure[]{
            \label{fig:tree3}
            \includegraphics[scale=0.33]{Tree3.png}
        }
    \end{center}
    \caption{Supervision View Example}
   \label{fig:supervisionview}
\end{figure*}

\subsubsection{A Partly Failed Safe Calculator}
\label{calculator_chaos_test}

In the hope that Chaos Monkey and Supervision View tests can reveal breaking 
points of a supervision tree, we modify the Safe Calculator example and run a 
test as follows.  Firstly, we run three safe calculators on three Beowulf 
nodes, under the supervision of a root actor using the {\tt OneForOne} strategy 
with {\tt Restart} action.  Secondly, we set different supervisor strategies 
for each safe calculator.  The first safe calculator, S1, restarts any failed 
child immediately.  This configuration simulates a quick restart process.
The second safe calculator, S2, computes a Fibonacci number in a naive way for 
about 10 seconds before restarting any failed child.  This configuration 
simulates 
a restart process which may take a noticeable time.  The third safe calculator, 
S3, stops the child when it fails.  Finally, we set-up the a Supervision View 
test which captures the supervision tree every 15 seconds, and a Chaos Monkey 
test which tries to kill a random child calculator every 3 seconds.

A test result, given in Figure \ref{fig:supervisionview}, gives the expected
tree structure at the beginning, 15 seconds and 30 seconds of the test.  Figure 
\ref{fig:tree1} shows that the application initialized three safe calculators as 
described.  In Figure \ref{fig:tree2}, S2 and its child are marked as dashed 
circles because it takes the view master more than 5 seconds to receive their 
responses.  From the test result itself, we cannot tell whether the delay is 
due to a blocked calculation or a network congestion.  Comparing to Figure 
\ref{fig:tree1}, the child of S3 is not shown in Figure \ref{fig:tree2} and 
Figure \ref{fig:tree3} because no response is received from it until the end of 
the test.  When the test ends, no response to the last request is received 
from S2 and its child.  Therefore, both S2 and its child are not shown in 
Figure \ref{fig:tree3}.  S1 and its child appear in all three Figures because 
either they never fail during the test or they are recovered from failures 
within a short time.




\subsubsection{BenchErl Examples with Different Supervisor Strategies}
\label{bencherl_chaos_test}

To test the behaviour of applications with internal states under 
different supervisor strategies, we apply the {\tt OneForOne} supervisor 
strategy with different failure actions to the 6 BenchErl examples and test 
those examples using Chaos Monkey and Supervision View.  The master node of 
each BenchErl test is initialized with an internal counter.  The internal 
counter decrease when the master node receives a finishing messages from its 
children.  The test application stops when the internal counter of the master 
node reaches 0.  We set the Chaos Monkey test with the {\tt Kill} mode and 
randomly kill a victim actor every second.  When the {\tt Escalate} action is 
applied to the master node, the test stops as soon as the first {\tt Kill} 
message sent from the Chaos Monkey test.  When the {\tt Stop} action is applied, 
the application does not stop and, eventually, the supervision view test only 
receives messages from the master node.  When the {\tt Restart} action is 
applied, the application does not stop but the Supervision View test receives 
messages from the master node and its children.  When the {\tt Resume} action is 
applied, all tests stops eventually with a longer run-time comparing to tests 
without Chaos Monkey and Supervision View tests.




\begin{comment}
\subsubsection{Limitation of Accelerated Software Reliability Test}

By following the Supervision Principle, software developers hope their 
applications can be tolerant of run-time exceptions.
\end{comment}